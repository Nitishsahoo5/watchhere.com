const OpenAI = require('openai');
const ffmpeg = require('fluent-ffmpeg');

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const extractVideoFrames = async (videoPath, count = 5) => {
  return new Promise((resolve, reject) => {
    const frames = [];
    const interval = 100 / count; // Extract frames at intervals
    
    for (let i = 0; i < count; i++) {
      const timestamp = `${interval * i}%`;
      const framePath = `/tmp/frame_${i}_${Date.now()}.jpg`;
      
      ffmpeg(videoPath)
        .screenshots({
          timestamps: [timestamp],
          filename: `frame_${i}_${Date.now()}.jpg`,
          folder: '/tmp',
          size: '320x240'
        })
        .on('end', () => frames.push(framePath))
        .on('error', reject);
    }
    
    setTimeout(() => resolve(frames), 3000); // Wait for all frames
  });
};

const analyzeVideoContent = async (videoPath) => {
  try {
    const frames = await extractVideoFrames(videoPath, 3);
    
    // Analyze frames with GPT-4 Vision (if available) or fallback
    const frameAnalysis = await Promise.all(
      frames.map(async (framePath) => {
        try {
          // This would use GPT-4 Vision API when available
          // For now, return placeholder analysis
          return {
            description: "Video frame showing content",
            objects: ["person", "background"],
            scene: "indoor/outdoor"
          };
        } catch (error) {
          return { description: "Unable to analyze frame", objects: [], scene: "unknown" };
        }
      })
    );

    return frameAnalysis;
  } catch (error) {
    console.error('Video analysis error:', error);
    return [];
  }
};

const generateVideoSummary = async (videoData) => {
  try {
    const { title, category, duration, frameAnalysis = [] } = videoData;
    
    const prompt = `Generate a compelling 2-3 sentence description for a ${category} video titled "${title}" that is ${Math.floor(duration / 60)} minutes long. 
    
    Frame analysis: ${frameAnalysis.map(f => f.description).join(', ')}
    
    Make it engaging and highlight what viewers will learn or enjoy. Keep it under 150 characters for social media.`;

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 100,
      temperature: 0.7
    });

    return response.choices[0].message.content.trim();
  } catch (error) {
    console.error('Summary generation error:', error);
    return `Discover amazing ${videoData.category.toLowerCase()} content in this ${Math.floor(videoData.duration / 60)}-minute video.`;
  }
};

const generateHashtags = async (title, category, summary) => {
  try {
    const prompt = `Generate 5-8 relevant hashtags for a video titled "${title}" in the ${category} category. Summary: ${summary}. Return as JSON array.`;

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 80
    });

    return JSON.parse(response.choices[0].message.content);
  } catch (error) {
    return [`#${category.toLowerCase()}`, '#video', '#content'];
  }
};

const generateVideoMetadata = async (videoPath, videoData) => {
  try {
    const frameAnalysis = await analyzeVideoContent(videoPath);
    const summary = await generateVideoSummary({ ...videoData, frameAnalysis });
    const hashtags = await generateHashtags(videoData.title, videoData.category, summary);

    return {
      summary,
      hashtags,
      frameAnalysis,
      autoGenerated: true,
      generatedAt: new Date()
    };
  } catch (error) {
    console.error('Metadata generation error:', error);
    return {
      summary: `Check out this ${videoData.category.toLowerCase()} video!`,
      hashtags: [`#${videoData.category.toLowerCase()}`],
      frameAnalysis: [],
      autoGenerated: false
    };
  }
};

module.exports = { generateVideoSummary, generateHashtags, generateVideoMetadata, analyzeVideoContent };